{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# on one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_width=data['data'][:,3] #data for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_flower=data['target'] # target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1,\n",
       "       0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2,\n",
       "       0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.2, 0.2, 0.2, 0.1, 0.2,\n",
       "       0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 1.4, 1.5,\n",
       "       1.5, 1.3, 1.5, 1.3, 1.6, 1. , 1.3, 1.4, 1. , 1.5, 1. , 1.4, 1.3,\n",
       "       1.4, 1.5, 1. , 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7,\n",
       "       1.5, 1. , 1.1, 1. , 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2,\n",
       "       1.4, 1.2, 1. , 1.3, 1.2, 1.3, 1.3, 1.1, 1.3, 2.5, 1.9, 2.1, 1.8,\n",
       "       2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2. , 1.9, 2.1, 2. , 2.4, 2.3, 1.8,\n",
       "       2.2, 2.3, 1.5, 2.3, 2. , 2. , 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6,\n",
       "       1.9, 2. , 2.2, 1.5, 1.4, 2.3, 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9,\n",
       "       2.3, 2.5, 2.3, 1.9, 2. , 2.3, 1.8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "petal_width #petal_width\n",
    "#convert in 2D before fitting to Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either flower is virginica \n",
    "target_flower=(data['target']==2).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_flower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train machine using Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic=LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# fitting to model\n",
    "logistic=logistic.fit(petal_width.reshape(len(petal_width),1),target_flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of the data on behalf of the Regression\n",
    "predict=logistic.predict(petal_width.reshape(len(petal_width),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not virginica\n"
     ]
    }
   ],
   "source": [
    "# printing the data\n",
    "predict=logistic.predict([[0.6]])\n",
    "if predict==1:\n",
    "    print(\"virginica\")\n",
    "else:\n",
    "    print(\"Not virginica\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [p-1,p]\n",
    "probability=logistic.predict_proba(petal_width.reshape(len(petal_width),1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.95988006, 0.04011994],\n",
       "       [0.96883275, 0.03116725],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.98129904, 0.01870096],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.98129904, 0.01870096],\n",
       "       [0.98129904, 0.01870096],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.95988006, 0.04011994],\n",
       "       [0.95988006, 0.04011994],\n",
       "       [0.96883275, 0.03116725],\n",
       "       [0.96883275, 0.03116725],\n",
       "       [0.96883275, 0.03116725],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.95988006, 0.04011994],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.94849246, 0.05150754],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.95988006, 0.04011994],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.95988006, 0.04011994],\n",
       "       [0.98129904, 0.01870096],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.98129904, 0.01870096],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.96883275, 0.03116725],\n",
       "       [0.96883275, 0.03116725],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.93409453, 0.06590547],\n",
       "       [0.95988006, 0.04011994],\n",
       "       [0.96883275, 0.03116725],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.97583795, 0.02416205],\n",
       "       [0.63576788, 0.36423212],\n",
       "       [0.57328164, 0.42671836],\n",
       "       [0.57328164, 0.42671836],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.57328164, 0.42671836],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.50836513, 0.49163487],\n",
       "       [0.83260447, 0.16739553],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.63576788, 0.36423212],\n",
       "       [0.83260447, 0.16739553],\n",
       "       [0.57328164, 0.42671836],\n",
       "       [0.83260447, 0.16739553],\n",
       "       [0.63576788, 0.36423212],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.63576788, 0.36423212],\n",
       "       [0.57328164, 0.42671836],\n",
       "       [0.83260447, 0.16739553],\n",
       "       [0.57328164, 0.42671836],\n",
       "       [0.79288598, 0.20711402],\n",
       "       [0.3798665 , 0.6201335 ],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.57328164, 0.42671836],\n",
       "       [0.74661143, 0.25338857],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.63576788, 0.36423212],\n",
       "       [0.63576788, 0.36423212],\n",
       "       [0.44316529, 0.55683471],\n",
       "       [0.57328164, 0.42671836],\n",
       "       [0.83260447, 0.16739553],\n",
       "       [0.79288598, 0.20711402],\n",
       "       [0.83260447, 0.16739553],\n",
       "       [0.74661143, 0.25338857],\n",
       "       [0.50836513, 0.49163487],\n",
       "       [0.57328164, 0.42671836],\n",
       "       [0.50836513, 0.49163487],\n",
       "       [0.57328164, 0.42671836],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.74661143, 0.25338857],\n",
       "       [0.63576788, 0.36423212],\n",
       "       [0.74661143, 0.25338857],\n",
       "       [0.83260447, 0.16739553],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.74661143, 0.25338857],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.79288598, 0.20711402],\n",
       "       [0.69398823, 0.30601177],\n",
       "       [0.08926522, 0.91073478],\n",
       "       [0.32040654, 0.67959346],\n",
       "       [0.21832015, 0.78167985],\n",
       "       [0.3798665 , 0.6201335 ],\n",
       "       [0.1769322 , 0.8230678 ],\n",
       "       [0.21832015, 0.78167985],\n",
       "       [0.44316529, 0.55683471],\n",
       "       [0.3798665 , 0.6201335 ],\n",
       "       [0.3798665 , 0.6201335 ],\n",
       "       [0.08926522, 0.91073478],\n",
       "       [0.26625766, 0.73374234],\n",
       "       [0.32040654, 0.67959346],\n",
       "       [0.21832015, 0.78167985],\n",
       "       [0.26625766, 0.73374234],\n",
       "       [0.11296058, 0.88703942],\n",
       "       [0.14196538, 0.85803462],\n",
       "       [0.3798665 , 0.6201335 ],\n",
       "       [0.1769322 , 0.8230678 ],\n",
       "       [0.14196538, 0.85803462],\n",
       "       [0.57328164, 0.42671836],\n",
       "       [0.14196538, 0.85803462],\n",
       "       [0.26625766, 0.73374234],\n",
       "       [0.26625766, 0.73374234],\n",
       "       [0.3798665 , 0.6201335 ],\n",
       "       [0.21832015, 0.78167985],\n",
       "       [0.3798665 , 0.6201335 ],\n",
       "       [0.3798665 , 0.6201335 ],\n",
       "       [0.3798665 , 0.6201335 ],\n",
       "       [0.21832015, 0.78167985],\n",
       "       [0.50836513, 0.49163487],\n",
       "       [0.32040654, 0.67959346],\n",
       "       [0.26625766, 0.73374234],\n",
       "       [0.1769322 , 0.8230678 ],\n",
       "       [0.57328164, 0.42671836],\n",
       "       [0.63576788, 0.36423212],\n",
       "       [0.14196538, 0.85803462],\n",
       "       [0.11296058, 0.88703942],\n",
       "       [0.3798665 , 0.6201335 ],\n",
       "       [0.3798665 , 0.6201335 ],\n",
       "       [0.21832015, 0.78167985],\n",
       "       [0.11296058, 0.88703942],\n",
       "       [0.14196538, 0.85803462],\n",
       "       [0.32040654, 0.67959346],\n",
       "       [0.14196538, 0.85803462],\n",
       "       [0.08926522, 0.91073478],\n",
       "       [0.14196538, 0.85803462],\n",
       "       [0.32040654, 0.67959346],\n",
       "       [0.26625766, 0.73374234],\n",
       "       [0.14196538, 0.85803462],\n",
       "       [0.3798665 , 0.6201335 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing to get sharp curve\n",
    "x=np.linspace(0,3,3000).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=logistic.predict_proba(x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01445589, 0.01449325, 0.0145307 , ..., 0.97407672, 0.97414276,\n",
       "       0.97420864])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x150d7d9d588>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virginica\n"
     ]
    }
   ],
   "source": [
    "# probabilty of the result\n",
    "predict=logistic.predict([[6]]) \n",
    "if predict==1:\n",
    "    print(\"virginica\")\n",
    "else:\n",
    "    print(\"Not virginica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# on Complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\premp\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trian_data=data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data=data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(trian_data,target_data,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic=LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\premp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logistic=logistic.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=logistic.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0 ][ 1  1 ][ 1  1 ][ 0  0 ][ 2  2 ][ 1  2 ][ 2  2 ][ 0  0 ][ 0  0 ][ 2  2 ][ 1  1 ][ 0  0 ][ 2  2 ][ 1  1 ][ 1  2 ][ 0  0 ][ 1  1 ][ 1  2 ][ 0  0 ][ 0  0 ][ 1  1 ][ 1  2 ][ 1  2 ][ 0  0 ][ 2  2 ][ 1  1 ][ 0  0 ][ 0  0 ][ 1  1 ][ 2  2 ][ 1  1 ][ 2  2 ][ 1  1 ][ 2  2 ][ 2  2 ][ 0  0 ][ 1  1 ][ 0  0 ][ 1  1 ][ 2  2 ][ 2  2 ][ 0  0 ][ 2  2 ][ 2  2 ][ 1  1 ]"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_test)):\n",
    "    print(\"[\",y_test[i],\"\",y_predict[i],\"]\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get actual and predict data\n",
    "actual=[data.target_names[p] for p in y_test]\n",
    "predict=[data.target_names[p] for p in y_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa -> setosa\n",
      "versicolor -> versicolor\n",
      "versicolor -> versicolor\n",
      "setosa -> setosa\n",
      "virginica -> virginica\n",
      "versicolor -> virginica\n",
      "virginica -> virginica\n",
      "setosa -> setosa\n",
      "setosa -> setosa\n",
      "virginica -> virginica\n",
      "versicolor -> versicolor\n",
      "setosa -> setosa\n",
      "virginica -> virginica\n",
      "versicolor -> versicolor\n",
      "versicolor -> virginica\n",
      "setosa -> setosa\n",
      "versicolor -> versicolor\n",
      "versicolor -> virginica\n",
      "setosa -> setosa\n",
      "setosa -> setosa\n",
      "versicolor -> versicolor\n",
      "versicolor -> virginica\n",
      "versicolor -> virginica\n",
      "setosa -> setosa\n",
      "virginica -> virginica\n",
      "versicolor -> versicolor\n",
      "setosa -> setosa\n",
      "setosa -> setosa\n",
      "versicolor -> versicolor\n",
      "virginica -> virginica\n",
      "versicolor -> versicolor\n",
      "virginica -> virginica\n",
      "versicolor -> versicolor\n",
      "virginica -> virginica\n",
      "virginica -> virginica\n",
      "setosa -> setosa\n",
      "versicolor -> versicolor\n",
      "setosa -> setosa\n",
      "versicolor -> versicolor\n",
      "virginica -> virginica\n",
      "virginica -> virginica\n",
      "setosa -> setosa\n",
      "virginica -> virginica\n",
      "virginica -> virginica\n",
      "versicolor -> versicolor\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(actual)):\n",
    "    print(actual[i],\"->\",predict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"accuracy :\",metrics.accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy checking manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(len(actual)):\n",
    "    if(actual[i]==predict[i]):\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 45)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count,len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40/45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 3.5, 1.4, 0.2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual-> seteso\n",
    "y_predict=logistic.predict([data['data'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa'], dtype='<U10')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names[y_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.permutation(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 16,  8, 12, 14, 15,  0,  6, 19,  3, 17,  1, 10,  5,  4, 11,  9,\n",
       "       18, 13,  7])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
